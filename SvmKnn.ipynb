{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, ParameterGrid, train_test_split, StratifiedShuffleSplit\n",
    "import ml_utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "TESTS_PATH = \"./tests/\"\n",
    "INFO_PATH = \"./tests/experiments_info\"\n",
    "DATASET_TEST_PATH = 'DBs/PenDigits/pendigits_te.txt'\n",
    "DATASET_PATH = 'DBs/PenDigits/pendigits_tr.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    feat_count = 16\n",
    "    data_path = DATASET_PATH # Impostare il percorso corretto\n",
    "    patterns, labels = ml_utilities.load_labeled_dataset_from_txt(data_path, feat_count)\n",
    "    test_path = DATASET_TEST_PATH\n",
    "    x_test = ml_utilities.load_unlabeled_dataset_from_txt(test_path, feature_count)\n",
    "    return patterns, labels, x_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def normalize_data(x_train, x_test):\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaler.fit(dataset_patterns)\n",
    "    x_train_normalized = scaler.fit_transform(x_train)\n",
    "    x_test_normalized = scaler.fit_transform(x_test)\n",
    "\n",
    "    return x_train_normalized, x_test_normalized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# def feature_extractor(x_grid):\n",
    "#     SIZE = x_grid.shape[1]\n",
    "#     activation = 'sigmoid'\n",
    "#     feature = Sequential()\n",
    "#\n",
    "#     feature.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (SIZE, SIZE, 1)))\n",
    "#     feature.add(BatchNormalization())\n",
    "#\n",
    "#     feature.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "#     feature.add(BatchNormalization())\n",
    "#     feature.add(MaxPool2D())\n",
    "#\n",
    "#     feature.add(Flatten())\n",
    "#\n",
    "#     return feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'SVC': {\n",
    "        'model': SVC( ),\n",
    "        'params' : {\n",
    "            'C': [2**i for i in range(-5,16)] + [1],  #Regularization parameter. Providing only two as SVM is slow\n",
    "            'kernel': ['rbf','linear'],\n",
    "            'gamma': [2**i for i in range(-5,16)] + [0.00009111627561154887],\n",
    "            'class_weight':['balanced', None],\n",
    "            'degree' : [1,2,3,4,5,6]\n",
    "        }\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params' : {\n",
    "            'n_neighbors': [1,3,5,7,9,11,13,15,17,19,21,23,25,27],\n",
    "            'weights': ['uniform','distance'],\n",
    "            'algorithm': [\"ball_tree\",\"kd_tree\",\"brute\"],\n",
    "            'metric': [\"minkowski\",\"euclidean\",\"l1\", \"l2\",\"manhattan\"],\n",
    "\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [2**i for i in range(-5,16)] + [1],  #Regularization. . Providing only two as LR can be slow\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "scores=[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataset: (442, 16)\n",
      "Shape labels: (442,)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento del dataset\n",
    "feature_count = 16\n",
    "dataset_path = 'DBs/PenDigits/pendigits_tr.txt'  # Impostare il percorso corretto\n",
    "\n",
    "dataset_patterns, dataset_labels = ml_utilities.load_labeled_dataset_from_txt(dataset_path, feature_count)\n",
    "print('Shape dataset:', dataset_patterns.shape)\n",
    "print('Shape labels:', dataset_labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 2.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\core.py\", line 1680, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [12:37:58] c:\\windows\\temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\common\\common.h:157: XGBoost version not compiled with GPU support.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[12:37:58] c:\\windows\\temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\common\\common.h:157: XGBoost version not compiled with GPU support.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mXGBoostError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [48]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_name, mp \u001B[38;5;129;01min\u001B[39;00m model_params\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# pipe = Pipeline([('classifier' , mp['model'])])\u001B[39;00m\n\u001B[0;32m     19\u001B[0m     grid \u001B[38;5;241m=\u001B[39m  RandomizedSearchCV(xgb,\n\u001B[0;32m     20\u001B[0m                                param_distributions\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m     21\u001B[0m                                cv\u001B[38;5;241m=\u001B[39mcross_val,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m                                return_train_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     25\u001B[0m                                random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m---> 27\u001B[0m     \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     scores\u001B[38;5;241m.\u001B[39mappend({\n\u001B[0;32m     29\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_test_size\u001B[39m\u001B[38;5;124m'\u001B[39m: data_test_size,\n\u001B[0;32m     30\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfolds\u001B[39m\u001B[38;5;124m'\u001B[39m: folds,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_params\u001B[39m\u001B[38;5;124m'\u001B[39m: grid\u001B[38;5;241m.\u001B[39mbest_params_,\n\u001B[0;32m     35\u001B[0m     })\n\u001B[0;32m     37\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(scores,columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_test_size\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfolds\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_score\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_params\u001B[39m\u001B[38;5;124m'\u001B[39m,])\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    924\u001B[0m refit_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    925\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 926\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    927\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    928\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\core.py:506\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    505\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 506\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\sklearn.py:1250\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1230\u001B[0m model, feval, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(xgb_model, eval_metric, params)\n\u001B[0;32m   1231\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[0;32m   1232\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m   1233\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1247\u001B[0m     label_transform\u001B[38;5;241m=\u001B[39mlabel_transform,\n\u001B[0;32m   1248\u001B[0m )\n\u001B[1;32m-> 1250\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1251\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1253\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1259\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1260\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1262\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\training.py:188\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(params, dtrain, num_boost_round\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, evals\u001B[38;5;241m=\u001B[39m(), obj\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, feval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    116\u001B[0m           maximize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, early_stopping_rounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, evals_result\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    117\u001B[0m           verbose_eval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, xgb_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001B[39;00m\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;124;03m\"\"\"Train a booster with given parameters.\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;124;03m    Booster : a trained booster model\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 188\u001B[0m     bst \u001B[38;5;241m=\u001B[39m \u001B[43m_train_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_boost_round\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxgb_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bst\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\training.py:81\u001B[0m, in \u001B[0;36m_train_internal\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m---> 81\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\core.py:1680\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1677\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_features(dtrain)\n\u001B[0;32m   1679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1680\u001B[0m     \u001B[43m_check_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1681\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1682\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1683\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1684\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Test\\lib\\site-packages\\xgboost\\core.py:218\u001B[0m, in \u001B[0;36m_check_call\u001B[1;34m(ret)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m\"\"\"Check the return value of C API call\u001B[39;00m\n\u001B[0;32m    208\u001B[0m \n\u001B[0;32m    209\u001B[0m \u001B[38;5;124;03mThis function will raise exception when error occurs.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;124;03m    return value from API calls\u001B[39;00m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m XGBoostError(py_str(_LIB\u001B[38;5;241m.\u001B[39mXGBGetLastError()))\n",
      "\u001B[1;31mXGBoostError\u001B[0m: [12:37:58] c:\\windows\\temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\common\\common.h:157: XGBoost version not compiled with GPU support."
     ]
    }
   ],
   "source": [
    "!conda create -n xgboost_env -c nvidia -c rapidsai py-xgboost cudatoolkit=10.2\n",
    "np.random.seed(42)\n",
    "\n",
    "x_train_raw, y_train, x_test_raw = read_data()\n",
    "x_train, x_test = normalize_data(x_train_raw,x_test_raw)\n",
    "for data_test_size in [0.2]:\n",
    "    for folds in [1]:\n",
    "        cross_val = StratifiedShuffleSplit(n_splits=folds, test_size=data_test_size, random_state=42)\n",
    "        xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic', nthread=1,tree_method='gpu_hist')\n",
    "        params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.02, 0.05]\n",
    "        }\n",
    "        for model_name, mp in model_params.items():\n",
    "            # pipe = Pipeline([('classifier' , mp['model'])])\n",
    "            grid =  RandomizedSearchCV(xgb,\n",
    "                                       param_distributions=params,\n",
    "                                       cv=cross_val,\n",
    "                                       n_jobs=16,\n",
    "                                       n_iter=2,\n",
    "                                       return_train_score=False,\n",
    "                                       random_state=42)\n",
    "\n",
    "            grid.fit(x_train,y_train)\n",
    "            scores.append({\n",
    "                'data_test_size': data_test_size,\n",
    "                'folds': folds,\n",
    "                'model': model_name,\n",
    "                'best_score': grid.best_score_,\n",
    "                'mean_test_score': grid.cv_results_['mean_test_score'],\n",
    "                'best_params': grid.best_params_,\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(scores,columns=['data_test_size','folds','model','best_score','mean_test_score','best_params',])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 1\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 2\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 3\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 4\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 5\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 6\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 7\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 8\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "fit completed\n",
      "data_test_size= 0.05 and folds = 9\n",
      "fit completed\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x_train, y_train, x_test = read_data()\n",
    "x_train, x_test = normalize_data(x_train,x_test)\n",
    "\n",
    "for data_test_size in[0.05]:\n",
    "    for folds in  np.arange(1, 10, 1):\n",
    "        cross_val = StratifiedShuffleSplit(n_splits=folds, test_size=data_test_size, random_state=42)\n",
    "        for model_name, mp in model_params.items():\n",
    "            grid =  GridSearchCV(estimator=mp['model'],\n",
    "                                 param_grid=mp['params'],\n",
    "                                 cv=cross_val,\n",
    "                                 n_jobs=16,\n",
    "                                 return_train_score=False)\n",
    "\n",
    "            grid.fit(x_train,y_train)\n",
    "            scores.append({\n",
    "                'data_test_size': data_test_size,\n",
    "                'folds': folds,\n",
    "                'model': model_name,\n",
    "                'best_score': grid.best_score_,\n",
    "                'mean_test_score': grid.cv_results_['mean_test_score'],\n",
    "                'best_params': grid.best_params_,\n",
    "            })\n",
    "            print(f\"fit completed\")\n",
    "        dd = pd.DataFrame(scores,columns=['data_test_size','folds','model','best_score','mean_test_score','best_params',])\n",
    "        print(f\"data_test_size= {data_test_size} and folds = {folds}\")\n",
    "        print(f\"fit completed\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "     data_test_size  folds                model  best_score  \\\n0              0.10      1                  SVC    0.933333   \n1              0.10      1           KNeighbors    0.888889   \n2              0.10      1  logistic_regression    0.777778   \n3              0.10      2                  SVC    0.866667   \n4              0.10      2           KNeighbors    0.855556   \n..              ...    ...                  ...         ...   \n508            0.05      8           KNeighbors    0.864130   \n509            0.05      8  logistic_regression    0.782609   \n510            0.05      9                  SVC    0.864734   \n511            0.05      9           KNeighbors    0.855072   \n512            0.05      9  logistic_regression    0.782609   \n\n                                       mean_test_score  \\\n0    [0.15555555555555556, 0.3111111111111111, 0.15...   \n1    [0.7555555555555555, 0.7555555555555555, 0.711...   \n2    [0.13333333333333333, 0.4666666666666667, 0.26...   \n3    [0.14444444444444443, 0.28888888888888886, 0.1...   \n4    [0.7333333333333334, 0.7333333333333334, 0.766...   \n..                                                 ...   \n508  [0.7663043478260869, 0.7663043478260869, 0.826...   \n509  [0.13043478260869565, 0.4782608695652174, 0.35...   \n510  [0.08695652173913043, 0.2657004830917874, 0.08...   \n511  [0.7536231884057971, 0.7536231884057971, 0.806...   \n512  [0.13043478260869565, 0.4734299516908213, 0.34...   \n\n                                           best_params  \n0    {'C': 0.125, 'class_weight': 'balanced', 'degr...  \n1    {'algorithm': 'ball_tree', 'metric': 'minkowsk...  \n2                          {'C': 0.5, 'penalty': 'l2'}  \n3    {'C': 1, 'class_weight': 'balanced', 'degree':...  \n4    {'algorithm': 'ball_tree', 'metric': 'minkowsk...  \n..                                                 ...  \n508  {'algorithm': 'ball_tree', 'metric': 'minkowsk...  \n509                          {'C': 1, 'penalty': 'l1'}  \n510  {'C': 1, 'class_weight': None, 'degree': 1, 'g...  \n511  {'algorithm': 'ball_tree', 'metric': 'minkowsk...  \n512                          {'C': 1, 'penalty': 'l1'}  \n\n[513 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data_test_size</th>\n      <th>folds</th>\n      <th>model</th>\n      <th>best_score</th>\n      <th>mean_test_score</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.10</td>\n      <td>1</td>\n      <td>SVC</td>\n      <td>0.933333</td>\n      <td>[0.15555555555555556, 0.3111111111111111, 0.15...</td>\n      <td>{'C': 0.125, 'class_weight': 'balanced', 'degr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.10</td>\n      <td>1</td>\n      <td>KNeighbors</td>\n      <td>0.888889</td>\n      <td>[0.7555555555555555, 0.7555555555555555, 0.711...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.10</td>\n      <td>1</td>\n      <td>logistic_regression</td>\n      <td>0.777778</td>\n      <td>[0.13333333333333333, 0.4666666666666667, 0.26...</td>\n      <td>{'C': 0.5, 'penalty': 'l2'}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.10</td>\n      <td>2</td>\n      <td>SVC</td>\n      <td>0.866667</td>\n      <td>[0.14444444444444443, 0.28888888888888886, 0.1...</td>\n      <td>{'C': 1, 'class_weight': 'balanced', 'degree':...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.10</td>\n      <td>2</td>\n      <td>KNeighbors</td>\n      <td>0.855556</td>\n      <td>[0.7333333333333334, 0.7333333333333334, 0.766...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>0.05</td>\n      <td>8</td>\n      <td>KNeighbors</td>\n      <td>0.864130</td>\n      <td>[0.7663043478260869, 0.7663043478260869, 0.826...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>0.05</td>\n      <td>8</td>\n      <td>logistic_regression</td>\n      <td>0.782609</td>\n      <td>[0.13043478260869565, 0.4782608695652174, 0.35...</td>\n      <td>{'C': 1, 'penalty': 'l1'}</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>0.05</td>\n      <td>9</td>\n      <td>SVC</td>\n      <td>0.864734</td>\n      <td>[0.08695652173913043, 0.2657004830917874, 0.08...</td>\n      <td>{'C': 1, 'class_weight': None, 'degree': 1, 'g...</td>\n    </tr>\n    <tr>\n      <th>511</th>\n      <td>0.05</td>\n      <td>9</td>\n      <td>KNeighbors</td>\n      <td>0.855072</td>\n      <td>[0.7536231884057971, 0.7536231884057971, 0.806...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>0.05</td>\n      <td>9</td>\n      <td>logistic_regression</td>\n      <td>0.782609</td>\n      <td>[0.13043478260869565, 0.4734299516908213, 0.34...</td>\n      <td>{'C': 1, 'penalty': 'l1'}</td>\n    </tr>\n  </tbody>\n</table>\n<p>513 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_pickle(TESTS_PATH+\"/Training\")\n",
    "dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "     data_test_size  folds                model  best_score  \\\n256            0.55      5           KNeighbors    0.799180   \n292            0.60      8           KNeighbors    0.783365   \n145            0.35      4           KNeighbors    0.830645   \n430            0.85      9           KNeighbors    0.713357   \n148            0.35      5           KNeighbors    0.823226   \n..              ...    ...                  ...         ...   \n212            0.45      8  logistic_regression    0.758166   \n398            0.80      7  logistic_regression    0.732849   \n209            0.45      7  logistic_regression    0.758794   \n206            0.45      6  logistic_regression    0.758794   \n512            0.05      9  logistic_regression    0.782609   \n\n                                       mean_test_score  \\\n256  [0.7475409836065573, 0.7475409836065573, 0.768...   \n292  [0.743421052631579, 0.743421052631579, 0.75187...   \n145  [0.7709677419354839, 0.7709677419354839, 0.779...   \n430  [0.6959219858156028, 0.6959219858156028, 0.688...   \n148  [0.76, 0.76, 0.7819354838709678, 0.79483870967...   \n..                                                 ...   \n212  [0.13190954773869348, 0.4491206030150754, 0.13...   \n398  [0.13276836158192087, 0.23930589184826473, 0.1...   \n209  [0.1313711414213927, 0.4465183058147882, 0.144...   \n206  [0.13149078726968175, 0.44388609715242877, 0.1...   \n512  [0.13043478260869565, 0.4734299516908213, 0.34...   \n\n                                           best_params  score  \n256  {'algorithm': 'ball_tree', 'metric': 'minkowsk...    1.0  \n292  {'algorithm': 'ball_tree', 'metric': 'minkowsk...    1.0  \n145  {'algorithm': 'ball_tree', 'metric': 'minkowsk...    1.0  \n430  {'algorithm': 'ball_tree', 'metric': 'minkowsk...    1.0  \n148  {'algorithm': 'ball_tree', 'metric': 'minkowsk...    1.0  \n..                                                 ...    ...  \n212                          {'C': 4, 'penalty': 'l2'}    0.0  \n398                          {'C': 4, 'penalty': 'l2'}    0.0  \n209                          {'C': 2, 'penalty': 'l2'}    0.0  \n206                          {'C': 2, 'penalty': 'l2'}    0.0  \n512                          {'C': 1, 'penalty': 'l1'}    0.0  \n\n[513 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data_test_size</th>\n      <th>folds</th>\n      <th>model</th>\n      <th>best_score</th>\n      <th>mean_test_score</th>\n      <th>best_params</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>0.55</td>\n      <td>5</td>\n      <td>KNeighbors</td>\n      <td>0.799180</td>\n      <td>[0.7475409836065573, 0.7475409836065573, 0.768...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>0.60</td>\n      <td>8</td>\n      <td>KNeighbors</td>\n      <td>0.783365</td>\n      <td>[0.743421052631579, 0.743421052631579, 0.75187...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>0.35</td>\n      <td>4</td>\n      <td>KNeighbors</td>\n      <td>0.830645</td>\n      <td>[0.7709677419354839, 0.7709677419354839, 0.779...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>0.85</td>\n      <td>9</td>\n      <td>KNeighbors</td>\n      <td>0.713357</td>\n      <td>[0.6959219858156028, 0.6959219858156028, 0.688...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>0.35</td>\n      <td>5</td>\n      <td>KNeighbors</td>\n      <td>0.823226</td>\n      <td>[0.76, 0.76, 0.7819354838709678, 0.79483870967...</td>\n      <td>{'algorithm': 'ball_tree', 'metric': 'minkowsk...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>0.45</td>\n      <td>8</td>\n      <td>logistic_regression</td>\n      <td>0.758166</td>\n      <td>[0.13190954773869348, 0.4491206030150754, 0.13...</td>\n      <td>{'C': 4, 'penalty': 'l2'}</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>0.80</td>\n      <td>7</td>\n      <td>logistic_regression</td>\n      <td>0.732849</td>\n      <td>[0.13276836158192087, 0.23930589184826473, 0.1...</td>\n      <td>{'C': 4, 'penalty': 'l2'}</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>0.45</td>\n      <td>7</td>\n      <td>logistic_regression</td>\n      <td>0.758794</td>\n      <td>[0.1313711414213927, 0.4465183058147882, 0.144...</td>\n      <td>{'C': 2, 'penalty': 'l2'}</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>0.45</td>\n      <td>6</td>\n      <td>logistic_regression</td>\n      <td>0.758794</td>\n      <td>[0.13149078726968175, 0.44388609715242877, 0.1...</td>\n      <td>{'C': 2, 'penalty': 'l2'}</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>0.05</td>\n      <td>9</td>\n      <td>logistic_regression</td>\n      <td>0.782609</td>\n      <td>[0.13043478260869565, 0.4734299516908213, 0.34...</td>\n      <td>{'C': 1, 'penalty': 'l1'}</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>513 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['score'] = 0\n",
    "# for SVC\n",
    "datawork = dataframe.loc[dataframe['model'] == \"SVC\"]\n",
    "dataframe['score'].update(datawork['best_params'].map(lambda x: SVC(**x).fit(x_train, y_train).score(x_train, y_train)))\n",
    "# for KNN\n",
    "datawork = dataframe.loc[dataframe['model'] == \"KNeighbors\"]\n",
    "dataframe['score'].update(datawork['best_params'].map(lambda x: KNeighborsClassifier(**x).fit(x_train, y_train).score(x_train, y_train)))# for KNN\n",
    "dataframe.sort_values(by='score', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "array([8., 4., 8., ..., 0., 8., 2.])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databest = dataframe.sort_values(by='best_score', ascending=True)\n",
    "best_classifier = SVC(**databest['best_params'][0])\n",
    "# Addestramento del classificatore\n",
    "best_classifier.fit(x_train, y_train)\n",
    "# Calcolo delle prediction\n",
    "predictions = best_classifier.predict(x_test)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
