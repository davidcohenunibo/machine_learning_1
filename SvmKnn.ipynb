{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,BatchNormalization,MaxPool2D\n",
    "from keras.layers import Dropout, Flatten\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "# Moduli di scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, ParameterGrid, train_test_split, StratifiedShuffleSplit, StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, ParameterGrid, train_test_split, StratifiedShuffleSplit\n",
    "import ml_utilities\n",
    "import ml_visualization\n",
    "import ml_utilities\n",
    "import ml_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "TESTS_PATH = \"./tests/\"\n",
    "INFO_PATH = \"./tests/experiments_info\"\n",
    "DATASET_TEST_PATH = 'DBs/PenDigits/pendigits_te.txt'\n",
    "DATASET_PATH = 'DBs/PenDigits/pendigits_tr.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    feat_count = 16\n",
    "    data_path = DATASET_PATH # Impostare il percorso corretto\n",
    "    patterns, labels = ml_utilities.load_labeled_dataset_from_txt(data_path, feat_count)\n",
    "    test_path = DATASET_TEST_PATH\n",
    "    x_test = ml_utilities.load_unlabeled_dataset_from_txt(test_path, feature_count)\n",
    "    return patterns, labels, x_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_data(dataset_patterns, test_x):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # alldata = np.concatenate((dataset_patterns, test_x))\n",
    "    # transformed_data = scaler.fit_transform(alldata)\n",
    "\n",
    "    transformed_data_train = scaler.fit_transform(dataset_patterns)\n",
    "    transformed_data_test = scaler.fit_transform(test_x)\n",
    "\n",
    "\n",
    "    # dataset_patterns = transformed_data[:442]\n",
    "    # test_x = transformed_data[442:]\n",
    "    return transformed_data_train, transformed_data_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def feature_extractor(x_grid):\n",
    "    SIZE = x_grid.shape[1]\n",
    "    activation = 'sigmoid'\n",
    "    feature = Sequential()\n",
    "\n",
    "    feature.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (SIZE, SIZE, 1)))\n",
    "    feature.add(BatchNormalization())\n",
    "\n",
    "    feature.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    feature.add(BatchNormalization())\n",
    "    feature.add(MaxPool2D())\n",
    "\n",
    "    feature.add(Flatten())\n",
    "\n",
    "    return feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1],  #Regularization parameter. Providing only two as SVM is slow\n",
    "            'kernel': ['rbf','linear']\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1],  #Regularization parameter. Providing only two as SVM is slow\n",
    "            'kernel': ['rbf','linear']\n",
    "        }\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params' : {\n",
    "            'n_neighbors': [1],\n",
    "            'weights': ['uniform'],\n",
    "            'algorithm': ['auto'],\n",
    "            'metric': ['minkowski'],\n",
    "\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1]  #Regularization. . Providing only two as LR can be slow\n",
    "        }\n",
    "    }\n",
    "}\n",
    "scores=[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataset: (442, 16)\n",
      "Shape labels: (442,)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento del dataset\n",
    "feature_count = 16\n",
    "dataset_path = 'DBs/PenDigits/pendigits_tr.txt'  # Impostare il percorso corretto\n",
    "\n",
    "dataset_patterns, dataset_labels = ml_utilities.load_labeled_dataset_from_txt(dataset_path, feature_count)\n",
    "print('Shape dataset:', dataset_patterns.shape)\n",
    "print('Shape labels:', dataset_labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x_train, y_train, x_test = read_data()\n",
    "x_grid, x_not_use, y_grid, y_not_use = train_test_split(x_train,y_train, test_size=0.2,random_state=42)\n",
    "for data_test_size in [0.2,0.3]:\n",
    "    for split in [1,2,3,4,5,6,7,8,9,10]:\n",
    "        cross_val = StratifiedShuffleSplit(n_splits=split, test_size=data_test_size, random_state=42)\n",
    "\n",
    "        for model_name, mp in model_params.items():\n",
    "            grid =  GridSearchCV(estimator=mp['model'],\n",
    "                                 param_grid=mp['params'],\n",
    "                                 cv=cross_val, n_jobs=16,\n",
    "                                 return_train_score=False)\n",
    "\n",
    "            grid.fit(x_train,y_train)\n",
    "            scores.append({\n",
    "                'data_test_size': data_test_size,\n",
    "                'split': split,\n",
    "                'model': model_name,\n",
    "                'best_score': grid.best_score_,\n",
    "                'mean_test_score': grid.cv_results_['mean_test_score'],\n",
    "                'best_params': grid.best_params_,\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(scores,columns=['data_test_size','split','model','best_score','mean_test_score','best_params',])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "    data_test_size  split                model  best_score  \\\n0              0.2      1                  svm    0.696629   \n1              0.2      1                  SVC    0.696629   \n2              0.2      1           KNeighbors    0.764045   \n3              0.2      1  logistic_regression    0.707865   \n4              0.2      2                  svm    0.735955   \n..             ...    ...                  ...         ...   \n75             0.3      9  logistic_regression    0.734336   \n76             0.3     10                  svm    0.729323   \n77             0.3     10                  SVC    0.729323   \n78             0.3     10           KNeighbors    0.780451   \n79             0.3     10  logistic_regression    0.726316   \n\n                             mean_test_score  \\\n0   [0.1348314606741573, 0.6966292134831461]   \n1   [0.1348314606741573, 0.6966292134831461]   \n2                       [0.7640449438202247]   \n3                       [0.7078651685393258]   \n4   [0.1348314606741573, 0.7359550561797753]   \n..                                       ...   \n75                      [0.7343358395989975]   \n76  [0.3398496240601504, 0.7293233082706767]   \n77  [0.3398496240601504, 0.7293233082706767]   \n78                       [0.780451127819549]   \n79                      [0.7263157894736841]   \n\n                                          best_params  \n0                        {'C': 1, 'kernel': 'linear'}  \n1                        {'C': 1, 'kernel': 'linear'}  \n2   {'algorithm': 'auto', 'metric': 'minkowski', '...  \n3                                            {'C': 1}  \n4                        {'C': 1, 'kernel': 'linear'}  \n..                                                ...  \n75                                           {'C': 1}  \n76                       {'C': 1, 'kernel': 'linear'}  \n77                       {'C': 1, 'kernel': 'linear'}  \n78  {'algorithm': 'auto', 'metric': 'minkowski', '...  \n79                                           {'C': 1}  \n\n[80 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data_test_size</th>\n      <th>split</th>\n      <th>model</th>\n      <th>best_score</th>\n      <th>mean_test_score</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.2</td>\n      <td>1</td>\n      <td>svm</td>\n      <td>0.696629</td>\n      <td>[0.1348314606741573, 0.6966292134831461]</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2</td>\n      <td>1</td>\n      <td>SVC</td>\n      <td>0.696629</td>\n      <td>[0.1348314606741573, 0.6966292134831461]</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.2</td>\n      <td>1</td>\n      <td>KNeighbors</td>\n      <td>0.764045</td>\n      <td>[0.7640449438202247]</td>\n      <td>{'algorithm': 'auto', 'metric': 'minkowski', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.2</td>\n      <td>1</td>\n      <td>logistic_regression</td>\n      <td>0.707865</td>\n      <td>[0.7078651685393258]</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.2</td>\n      <td>2</td>\n      <td>svm</td>\n      <td>0.735955</td>\n      <td>[0.1348314606741573, 0.7359550561797753]</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.3</td>\n      <td>9</td>\n      <td>logistic_regression</td>\n      <td>0.734336</td>\n      <td>[0.7343358395989975]</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.3</td>\n      <td>10</td>\n      <td>svm</td>\n      <td>0.729323</td>\n      <td>[0.3398496240601504, 0.7293233082706767]</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.3</td>\n      <td>10</td>\n      <td>SVC</td>\n      <td>0.729323</td>\n      <td>[0.3398496240601504, 0.7293233082706767]</td>\n      <td>{'C': 1, 'kernel': 'linear'}</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.3</td>\n      <td>10</td>\n      <td>KNeighbors</td>\n      <td>0.780451</td>\n      <td>[0.780451127819549]</td>\n      <td>{'algorithm': 'auto', 'metric': 'minkowski', '...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.3</td>\n      <td>10</td>\n      <td>logistic_regression</td>\n      <td>0.726316</td>\n      <td>[0.7263157894736841]</td>\n      <td>{'C': 1}</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
